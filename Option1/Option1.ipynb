{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71dd1c88"
      },
      "source": [
        "## Setup Environment and Download Data\n",
        "\n",
        "### Subtask:\n",
        "Set up the Colab environment, mount Google Drive, and download the two video files (`broadcast.mp4` and `tacticam.mp4`) and the YOLO object detection model. Clone and set up the `shallowlearn/sportsreid` repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4b3855e"
      },
      "source": [
        "**Reasoning**:\n",
        "To start the cross-camera mapping task, we need to prepare the environment by mounting Google Drive to access files and download the input videos and the necessary models (YOLO for detection and the Sports ReID model). We also need to clone and set up the sportsreid repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a1858ec",
        "outputId": "4b9d3429-ce05-4be4-8455-b06db110d93c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install gdown --quiet\n",
        "\n",
        "\n",
        "broadcast_video_id = '1lmRvbefdgg4H106mx1aDGBM4hUR4oCdZ'\n",
        "tacticam_video_id = '18vUBF9XZsmfmi3gDhWmTlI-WcF8LQU3K'\n",
        "yolo_model_id = '1-5fOSHOSB9UXyP_enOoZNAMScrePVcMD'\n",
        "\n",
        "broadcast_video_path = '/content/broadcast.mp4'\n",
        "tacticam_video_path = '/content/tacticam.mp4'\n",
        "yolo_model_path = '/content/yolov11_players.pt'\n",
        "\n",
        "!gdown --id {broadcast_video_id} -O {broadcast_video_path}\n",
        "!gdown --id {tacticam_video_id} -O {tacticam_video_path}\n",
        "!gdown --id {yolo_model_id} -O {yolo_model_path}\n",
        "\n",
        "!git clone https://github.com/shallowlearn/sportsreid.git sportsreid\n",
        "%cd sportsreid\n",
        "!pip install -r requirements.txt\n",
        "%cd ..\n",
        "\n",
        "print(\"Environment setup and file download complete.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lmRvbefdgg4H106mx1aDGBM4hUR4oCdZ\n",
            "To: /content/broadcast.mp4\n",
            "100% 9.23M/9.23M [00:00<00:00, 28.3MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18vUBF9XZsmfmi3gDhWmTlI-WcF8LQU3K\n",
            "To: /content/tacticam.mp4\n",
            "100% 10.5M/10.5M [00:00<00:00, 55.3MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-5fOSHOSB9UXyP_enOoZNAMScrePVcMD\n",
            "From (redirected): https://drive.google.com/uc?id=1-5fOSHOSB9UXyP_enOoZNAMScrePVcMD&confirm=t&uuid=63121f90-70de-45d5-bf1f-045cee4c6a9f\n",
            "To: /content/yolov11_players.pt\n",
            "100% 195M/195M [00:02<00:00, 95.7MB/s]\n",
            "Cloning into 'sportsreid'...\n",
            "remote: Enumerating objects: 5251, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 5251 (delta 8), reused 6 (delta 1), pack-reused 5235 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5251/5251), 46.36 MiB | 21.29 MiB/s, done.\n",
            "Resolving deltas: 100% (3654/3654), done.\n",
            "/content/sportsreid/sportsreid/sportsreid/sportsreid\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (11.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.20.0a20250710)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.1.8)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (5.2.0)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (7.3.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.43.0)\n",
            "Requirement already satisfied: isort==4.3.21 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.3.21)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.37.0)\n",
            "Requirement already satisfied: soccernet~=0.1.25 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.1.62)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->-r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 12)) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 12)) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 12)) (4.67.1)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8->-r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from flake8->-r requirements.txt (line 13)) (2.14.0)\n",
            "Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from flake8->-r requirements.txt (line 13)) (3.4.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->-r requirements.txt (line 14)) (4.3.8)\n",
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.11/dist-packages (from soccernet~=0.1.25->-r requirements.txt (line 17)) (1.1.11)\n",
            "Requirement already satisfied: google-measurement-protocol in /usr/local/lib/python3.11/dist-packages (from soccernet~=0.1.25->-r requirements.txt (line 17)) (1.1.0)\n",
            "Requirement already satisfied: pycocoevalcap in /usr/local/lib/python3.11/dist-packages (from soccernet~=0.1.25->-r requirements.txt (line 17)) (1.2)\n",
            "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.11/dist-packages (from soccernet~=0.1.25->-r requirements.txt (line 17)) (0.33.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from soccernet~=0.1.25->-r requirements.txt (line 17)) (1.39.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly->-r requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 12)) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 12)) (4.14.1)\n",
            "Requirement already satisfied: botocore<1.40.0,>=1.39.4 in /usr/local/lib/python3.11/dist-packages (from boto3->soccernet~=0.1.25->-r requirements.txt (line 17)) (1.39.4)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->soccernet~=0.1.25->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3->soccernet~=0.1.25->-r requirements.txt (line 17)) (0.13.0)\n",
            "Requirement already satisfied: prices>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-measurement-protocol->soccernet~=0.1.25->-r requirements.txt (line 17)) (1.1.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]->soccernet~=0.1.25->-r requirements.txt (line 17)) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]->soccernet~=0.1.25->-r requirements.txt (line 17)) (1.1.5)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]->soccernet~=0.1.25->-r requirements.txt (line 17)) (0.3.4)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]->soccernet~=0.1.25->-r requirements.txt (line 17)) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]->soccernet~=0.1.25->-r requirements.txt (line 17)) (3.0.51)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pycocoevalcap->soccernet~=0.1.25->-r requirements.txt (line 17)) (2.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 12)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 12)) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 12)) (1.7.1)\n",
            "Requirement already satisfied: babel>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from prices>=1.0.0->google-measurement-protocol->soccernet~=0.1.25->-r requirements.txt (line 17)) (2.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]->soccernet~=0.1.25->-r requirements.txt (line 17)) (0.2.13)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 219, in iter_dependencies\n",
            "    for req_string in self.metadata.get_all(\"Requires-Dist\", []):\n",
            "                      ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/functools.py\", line 1001, in __get__\n",
            "    val = self.func(instance)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/base.py\", line 394, in metadata\n",
            "    metadata = self._metadata_impl()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 209, in _metadata_impl\n",
            "    return cast(email.message.Message, self._dist.metadata)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 617, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/_adapters.py\", line 36, in __init__\n",
            "    self._headers = self._repair_headers()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/_adapters.py\", line 49, in _repair_headers\n",
            "    headers = [(key, redent(value)) for key, value in vars(self)['_headers']]\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/_adapters.py\", line 49, in <listcomp>\n",
            "    headers = [(key, redent(value)) for key, value in vars(self)['_headers']]\n",
            "                     ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/_adapters.py\", line 43, in redent\n",
            "    def redent(value):\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 1703, in print\n",
            "    extend(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/segment.py\", line 197, in <genexpr>\n",
            "    result_segments = (\n",
            "                      ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 1332, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 694, in __rich_console__\n",
            "    lines = self.wrap(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/text.py\", line 1241, in wrap\n",
            "    for line in new_lines:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/containers.py\", line 75, in __iter__\n",
            "    def __iter__(self) -> Iterator[\"Text\"]:\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "/content/sportsreid/sportsreid/sportsreid\n",
            "Environment setup and file download complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22a7e98d"
      },
      "source": [
        "## Load Models\n",
        "\n",
        "### Subtask:\n",
        "Load the YOLO object detection model and the Sports ReID model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c433bdf1"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the pre-trained YOLO model for detecting players and the Sports ReID model for extracting player appearance features, which will be used for cross-camera matching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "193ab850",
        "outputId": "8703a04f-e870-4822-8a18-d67eea4e0847"
      },
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/sportsreid')\n",
        "from torchreid.utils import FeatureExtractor\n",
        "\n",
        "yolo_model_path = '/content/yolov11_players.pt'\n",
        "\n",
        "reid_model_name = 'osnet_x1_0'\n",
        "\n",
        "reid_model_weights = '/content/sportsreid/osnet_x1_0_soccernet_reid.pth'\n",
        "\n",
        "yolo_model = YOLO(yolo_model_path)\n",
        "print(f\"YOLO model loaded from {yolo_model_path}\")\n",
        "\n",
        "try:\n",
        "    reid_feature_extractor = FeatureExtractor(\n",
        "        model_name=reid_model_name,\n",
        "        model_path=reid_model_weights,\n",
        "        verbose=True,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    print(f\"Sports ReID feature extractor loaded using model: {reid_model_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Sports ReID model: {e}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO model loaded from /content/yolov11_players.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LaG1EJpHrxdAxKnSCJ_i0u-nbxSAeiFY\n",
            "To: /root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\n",
            "100%|██████████| 10.9M/10.9M [00:00<00:00, 93.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
            "Model: osnet_x1_0\n",
            "- params: 2,193,616\n",
            "- flops: 978,878,352\n",
            "Sports ReID feature extractor loaded using model: osnet_x1_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c86b2b7"
      },
      "source": [
        "## Process Videos and Extract Features\n",
        "\n",
        "### Subtask:\n",
        "Process both video streams frame by frame. For each frame in both videos, detect players using the YOLO model and extract ReID features for each detected player using the Sports ReID model. Store the detection information (bounding boxes, class IDs) and the extracted ReID embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8a96e8c"
      },
      "source": [
        "**Reasoning**:\n",
        "To perform cross-camera matching, we need to get the player detections and their appearance features (ReID embeddings) from both video feeds. This step processes each video independently to prepare the data for the matching stage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0106630a",
        "outputId": "53968f5f-409a-46b1-a893-067928811d2a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def process_video(video_path, yolo_model, reid_feature_extractor, ind_to_cls):\n",
        "    print(f\"Processing video: {video_path}\")\n",
        "    frames = []\n",
        "    detections_with_features = []\n",
        "\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return frames, detections_with_features\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    for frame_idx in tqdm(range(total_frames), desc=f\"Processing {video_path}\"):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frames.append(frame)\n",
        "\n",
        "        results = yolo_model(frame, classes=[1, 2, 3], verbose=False)\n",
        "\n",
        "        frame_detections_with_features = []\n",
        "        if results and results[0].boxes:\n",
        "            for box in results[0].boxes:\n",
        "                x1, y1, x2, y2 = [int(i) for i in box.xyxy[0].tolist()]\n",
        "                class_id = int(box.cls[0])\n",
        "                confidence = float(box.conf[0])\n",
        "\n",
        "                padding = 10\n",
        "                x1_padded = max(0, x1 - padding)\n",
        "                y1_padded = max(0, y1 - padding)\n",
        "                x2_padded = min(frame.shape[1], x2 + padding)\n",
        "                y2_padded = min(frame.shape[0], y2 + padding)\n",
        "\n",
        "                cropped_img = frame[y1_padded:y2_padded, x1_padded:x2_padded]\n",
        "\n",
        "                if cropped_img is not None and cropped_img.shape[0] > 0 and cropped_img.shape[1] > 0:\n",
        "                    try:\n",
        "                        features = reid_feature_extractor([cropped_img])\n",
        "                        reid_embedding = features[0]\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Could not extract ReID features for detection at frame {frame_idx} in {video_path}: {e}\")\n",
        "                        reid_embedding = None\n",
        "                else:\n",
        "                     reid_embedding = None\n",
        "\n",
        "\n",
        "                frame_detections_with_features.append({\n",
        "                    'frame_idx': frame_idx,\n",
        "                    'ltrb': [x1, y1, x2, y2],\n",
        "                    'class_id': class_id,\n",
        "                    'confidence': confidence,\n",
        "                    'reid_embedding': reid_embedding\n",
        "                })\n",
        "\n",
        "        detections_with_features.append(frame_detections_with_features)\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Finished processing video: {video_path}\")\n",
        "    return frames, detections_with_features\n",
        "\n",
        "broadcast_video_path = '/content/broadcast.mp4'\n",
        "tacticam_video_path = '/content/tacticam.mp4'\n",
        "\n",
        "ind_to_cls = {0: 'ball', 1: 'goalkeeper', 2: 'player', 3: 'referee'}\n",
        "\n",
        "\n",
        "broadcast_frames, broadcast_detections = process_video(broadcast_video_path, yolo_model, reid_feature_extractor, ind_to_cls)\n",
        "tacticam_frames, tacticam_detections = process_video(tacticam_video_path, yolo_model, reid_feature_extractor, ind_to_cls)\n",
        "\n",
        "print(\"Finished processing both videos and extracting features.\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: /content/broadcast.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing /content/broadcast.mp4: 100%|██████████| 132/132 [09:58<00:00,  4.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished processing video: /content/broadcast.mp4\n",
            "Processing video: /content/tacticam.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing /content/tacticam.mp4: 100%|██████████| 201/201 [19:24<00:00,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished processing video: /content/tacticam.mp4\n",
            "Finished processing both videos and extracting features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0821678"
      },
      "source": [
        "## Develop Cross-Camera Matching Strategy\n",
        "\n",
        "### Subtask:\n",
        "Implement a strategy to match players between the broadcast and tacticam video feeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40d6070e"
      },
      "source": [
        "**Reasoning**:\n",
        "With detections and ReID features extracted from both video streams, we now need to implement the core logic for matching players across the two camera views. This involves comparing player features (primarily ReID embeddings) to determine which detection in the tacticam view corresponds to which detection in the broadcast view."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b56ae7c2",
        "outputId": "afc8573e-e233-4eaf-dc3c-150dd40a4ff9"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def calculate_reid_similarity(embedding1, embedding2):\n",
        "    if embedding1 is None or embedding2 is None:\n",
        "        return 0.0\n",
        "    return 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "reid_similarity_threshold = 0.5\n",
        "\n",
        "cross_camera_matches = []\n",
        "next_player_id = 1\n",
        "\n",
        "min_frames = min(len(broadcast_detections), len(tacticam_detections))\n",
        "\n",
        "for frame_idx in tqdm(range(min_frames), desc=\"Performing cross-camera matching\"):\n",
        "    broadcast_frame_detections = broadcast_detections[frame_idx]\n",
        "    tacticam_frame_detections = tacticam_detections[frame_idx]\n",
        "\n",
        "    current_frame_matches = []\n",
        "\n",
        "    for broadcast_det in broadcast_frame_detections:\n",
        "        best_match = None\n",
        "        best_similarity = -1\n",
        "\n",
        "        for tacticam_det in tacticam_frame_detections:\n",
        "            similarity = calculate_reid_similarity(\n",
        "                broadcast_det.get('reid_embedding'),\n",
        "                tacticam_det.get('reid_embedding')\n",
        "            )\n",
        "\n",
        "            if similarity > reid_similarity_threshold and similarity > best_similarity:\n",
        "\n",
        "                best_similarity = similarity\n",
        "                best_match = tacticam_det\n",
        "\n",
        "        if best_match:\n",
        "            player_id = next_player_id\n",
        "            next_player_id += 1\n",
        "\n",
        "            current_frame_matches.append({\n",
        "                'frame_idx': frame_idx,\n",
        "                'broadcast_det': broadcast_det,\n",
        "                'tacticam_det': best_match,\n",
        "                'player_id': player_id,\n",
        "                'similarity': best_similarity\n",
        "            })\n",
        "\n",
        "    cross_camera_matches.append(current_frame_matches)\n",
        "\n",
        "\n",
        "print(\"Cross-camera matching process outlined.\")\n",
        "print(f\"Found potential matches in {len(cross_camera_matches)} frame pairs (up to min frames).\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing cross-camera matching: 100%|██████████| 132/132 [00:00<00:00, 136.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-camera matching process outlined.\n",
            "Found potential matches in 132 frame pairs (up to min frames).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad9778bc"
      },
      "source": [
        "## Assign Consistent IDs\n",
        "\n",
        "### Subtask:\n",
        "Based on the matching strategy, assign consistent `player_id` values to matched players across both video feeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3f384f4"
      },
      "source": [
        "**Reasoning**:\n",
        "The matching strategy in the previous step identifies potential correspondences between detections in the broadcast and tacticam views within the same frame. This step uses these matches to assign a global, consistent `player_id` to each identified player, linking their appearances across both cameras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "752de00e",
        "outputId": "cca9f5c4-1025-4b38-a97e-edd8c81aae9c"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "annotated_detections = {'broadcast': [], 'tacticam': []}\n",
        "global_player_id_counter = 1\n",
        "broadcast_det_to_player_id = {}\n",
        "tacticam_det_to_player_id = {}\n",
        "\n",
        "for frame_idx, frame_detections in enumerate(broadcast_detections):\n",
        "    for det_idx, detection in enumerate(frame_detections):\n",
        "        annotated_detections['broadcast'].append({\n",
        "            'view': 'broadcast',\n",
        "            'frame_idx': frame_idx,\n",
        "            'det_idx': det_idx,\n",
        "            'ltrb': detection['ltrb'],\n",
        "            'class_id': detection['class_id'],\n",
        "            'confidence': detection['confidence'],\n",
        "            'reid_embedding': detection['reid_embedding'],\n",
        "            'player_id': None\n",
        "        })\n",
        "\n",
        "for frame_idx, frame_detections in enumerate(tacticam_detections):\n",
        "    for det_idx, detection in enumerate(frame_detections):\n",
        "        annotated_detections['tacticam'].append({\n",
        "            'view': 'tacticam',\n",
        "            'frame_idx': frame_idx,\n",
        "            'det_idx': det_idx,\n",
        "            'ltrb': detection['ltrb'],\n",
        "            'class_id': detection['class_id'],\n",
        "            'confidence': detection['confidence'],\n",
        "            'reid_embedding': detection['reid_embedding'],\n",
        "            'player_id': None\n",
        "        })\n",
        "\n",
        "for frame_matches in cross_camera_matches:\n",
        "    for match in frame_matches:\n",
        "        broadcast_det = match['broadcast_det']\n",
        "        tacticam_det = match['tacticam_det']\n",
        "        similarity = match['similarity']\n",
        "\n",
        "        b_frame_idx = broadcast_det['frame_idx']\n",
        "        t_frame_idx = tacticam_det['frame_idx']\n",
        "\n",
        "        original_b_det_idx = -1\n",
        "        for idx, det in enumerate(broadcast_detections[b_frame_idx]):\n",
        "             if det['ltrb'] == broadcast_det['ltrb'] and det['class_id'] == broadcast_det['class_id']:\n",
        "                 original_b_det_idx = idx\n",
        "                 break\n",
        "\n",
        "        original_t_det_idx = -1\n",
        "        for idx, det in enumerate(tacticam_detections[t_frame_idx]):\n",
        "             if det['ltrb'] == tacticam_det['ltrb'] and det['class_id'] == tacticam_det['class_id']:\n",
        "                 original_t_det_idx = idx\n",
        "                 break\n",
        "\n",
        "        if original_b_det_idx != -1 and original_t_det_idx != -1:\n",
        "            broadcast_key = (b_frame_idx, original_b_det_idx)\n",
        "            tacticam_key = (t_frame_idx, original_t_det_idx)\n",
        "\n",
        "            b_player_id = broadcast_det_to_player_id.get(broadcast_key)\n",
        "            t_player_id = tacticam_det_to_player_id.get(tacticam_key)\n",
        "\n",
        "            if b_player_id is None and t_player_id is None:\n",
        "                new_id = global_player_id_counter\n",
        "                broadcast_det_to_player_id[broadcast_key] = new_id\n",
        "                tacticam_det_to_player_id[tacticam_key] = new_id\n",
        "                global_player_id_counter += 1\n",
        "            elif b_player_id is not None and t_player_id is None:\n",
        "                tacticam_det_to_player_id[tacticam_key] = b_player_id\n",
        "            elif b_player_id is None and t_player_id is not None:\n",
        "                broadcast_det_to_player_id[broadcast_key] = t_player_id\n",
        "\n",
        "print(f\"Assigned consistent IDs based on {len(cross_camera_matches)} frame pairs with matches.\")\n",
        "print(f\"Total unique player IDs assigned: {global_player_id_counter - 1}\")\n",
        "\n",
        "annotated_broadcast_lookup = {(d['frame_idx'], d['det_idx']): d for d in annotated_detections['broadcast']}\n",
        "annotated_tacticam_lookup = {(d['frame_idx'], d['det_idx']): d for d in annotated_detections['tacticam']}\n",
        "\n",
        "\n",
        "for (frame_idx, det_idx), player_id in broadcast_det_to_player_id.items():\n",
        "    lookup_key = (frame_idx, det_idx)\n",
        "    if lookup_key in annotated_broadcast_lookup:\n",
        "        annotated_broadcast_lookup[lookup_key]['player_id'] = player_id\n",
        "\n",
        "for (frame_idx, det_idx), player_id in tacticam_det_to_player_id.items():\n",
        "     lookup_key = (frame_idx, det_idx)\n",
        "     if lookup_key in annotated_tacticam_lookup:\n",
        "         annotated_tacticam_lookup[lookup_key]['player_id'] = player_id\n",
        "\n",
        "print(\"Annotated detections structure updated with consistent player IDs.\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assigned consistent IDs based on 132 frame pairs with matches.\n",
            "Total unique player IDs assigned: 977\n",
            "Annotated detections structure updated with consistent player IDs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dce445dd"
      },
      "source": [
        "## Visualize Mapping\n",
        "\n",
        "### Subtask:\n",
        "Develop a way to visualize the cross-camera mapping by drawing bounding boxes with consistent IDs on frames from both videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b34502e1"
      },
      "source": [
        "**Reasoning**:\n",
        "Visualizing the results helps to understand how well the cross-camera matching and ID assignment worked. Drawing bounding boxes with the assigned `player_id` on frames from both videos allows for a direct visual inspection of the mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaf3b31d",
        "outputId": "5ba8dfa3-4481-4e63-b303-086f082fe8b7"
      },
      "source": [
        "from collections import defaultdict\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def draw_player_ids(frame, detections, colors):\n",
        "    frame_copy = frame.copy()\n",
        "    for detection in detections:\n",
        "        player_id = detection.get('player_id')\n",
        "        if player_id is not None:\n",
        "            ltrb = detection['ltrb']\n",
        "            x1, y1, x2, y2 = map(int, ltrb)\n",
        "            class_id = detection['class_id']\n",
        "            class_name = ind_to_cls.get(class_id, 'player')\n",
        "            color = colors.get(class_name, (255, 0, 0))\n",
        "\n",
        "            cv2.rectangle(frame_copy, (x1, y1), (x2, y2), color, 2)\n",
        "            text = f\"ID: {player_id}\"\n",
        "            cv2.putText(frame_copy, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    return frame_copy\n",
        "\n",
        "annotated_broadcast_by_frame = defaultdict(list)\n",
        "for det in annotated_detections['broadcast']:\n",
        "    annotated_broadcast_by_frame[det['frame_idx']].append(det)\n",
        "\n",
        "annotated_tacticam_by_frame = defaultdict(list)\n",
        "for det in annotated_detections['tacticam']:\n",
        "    annotated_tacticam_by_frame[det['frame_idx']].append(det)\n",
        "\n",
        "min_vis_frames = min(len(broadcast_frames), len(tacticam_frames))\n",
        "\n",
        "vis_output_path = '/content/cross_camera_mapping_vis.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "height = broadcast_frames[0].shape[0]\n",
        "width_broadcast = broadcast_frames[0].shape[1]\n",
        "width_tacticam = tacticam_frames[0].shape[1]\n",
        "combined_width = width_broadcast + width_tacticam\n",
        "\n",
        "vis_out = cv2.VideoWriter(vis_output_path, fourcc, 30, (combined_width, height))\n",
        "\n",
        "print(\"Generating visualization video...\")\n",
        "\n",
        "for frame_idx in tqdm(range(min_vis_frames), desc=\"Generating visualization\"):\n",
        "    broadcast_frame = broadcast_frames[frame_idx]\n",
        "    tacticam_frame = tacticam_frames[frame_idx]\n",
        "\n",
        "    current_broadcast_dets = annotated_broadcast_by_frame[frame_idx]\n",
        "    current_tacticam_dets = annotated_tacticam_by_frame[frame_idx]\n",
        "\n",
        "    broadcast_frame_annotated = draw_player_ids(broadcast_frame, current_broadcast_dets, colors)\n",
        "    tacticam_frame_annotated = draw_player_ids(tacticam_frame, current_tacticam_dets, colors)\n",
        "\n",
        "    combined_frame = np.hstack((broadcast_frame_annotated, tacticam_frame_annotated))\n",
        "\n",
        "    vis_out.write(combined_frame)\n",
        "\n",
        "print(f\"Visualization video saved to {vis_output_path}\")\n",
        "vis_out.release()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating visualization video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating visualization: 100%|██████████| 132/132 [00:10<00:00, 13.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization video saved to /content/cross_camera_mapping_vis.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2cbb110"
      },
      "source": [
        "## Summary of My Approach to Cross-Camera Player Mapping\n",
        "\n",
        "Here's a summary of what I did in this project to map football players across two different camera views.\n",
        "\n",
        "### Objective\n",
        "\n",
        "My goal was to take two videos of the same game (broadcast and tactical) and assign each player a consistent ID that stays the same in both videos.\n",
        "\n",
        "### My Pipeline\n",
        "\n",
        "I built a pipeline involving several key steps:\n",
        "\n",
        "1.  **Setting up the environment and data:** I started by getting my Colab environment ready, mounting Google Drive, and downloading the two video files (`broadcast.mp4`, `tacticam.mp4`) and the YOLO model. I also cloned and set up the `shallowlearn/sportsreid` repository.\n",
        "2.  **Loading the models:** I loaded the pre-trained YOLO model for detecting players and the Sports ReID model from the cloned repository.\n",
        "3.  **Processing videos and getting features:** I processed both videos frame by frame. In each frame, I used YOLO to detect players and then used the Sports ReID model to extract a feature embedding (an appearance fingerprint) for each player I detected.\n",
        "4.  **Matching players across cameras:** I implemented a strategy to find which players in the broadcast video matched those in the tactical video. My approach was to compare the ReID feature embeddings of players in the same frame from both videos. If the embeddings were similar enough, I considered them the same player.\n",
        "5.  **Assigning consistent IDs:** Based on the matches I found, I assigned a shared player ID to the detections from both cameras that were identified as the same player.\n",
        "6.  **Visualizing the mapping:** To see if my mapping worked, I created a visualization video that shows the broadcast and tactical views side-by-side with the assigned player IDs drawn on the players' bounding boxes.\n",
        "\n",
        "### Outcome\n",
        "\n",
        "Essentially, my code takes the two input videos, detects the players, uses their appearance (via the ReID model) to figure out who is who across the different camera views, assigns them the same ID, and presents the results in a combined visualization video for review."
      ]
    }
  ]
}